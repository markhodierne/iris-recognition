{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ls3RZpE-G7uU"
   },
   "source": [
    "# **Species Classification â€” Iris Flower Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwtN8nxDEXHM"
   },
   "source": [
    "Mark Hodierne  \n",
    "ML Project Portfolio  \n",
    "7th March 2024  \n",
    "https://github.com/markhodierne/iris-recognition  \n",
    "https://www.linkedin.com/in/markhodierne  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAN7AM_6HQMl"
   },
   "source": [
    "---\n",
    "\n",
    "#### ***Status: PROJECT COMPLETE***\n",
    "\n",
    "1. Neural Network built.\n",
    "1. Optimization - experimented with size of hidden layer, learning rates, number of epochs and batch size.\n",
    "3. Performance of model optimizations analyzed and opportunities for further improvements identified.\n",
    "4. Conclusions complete, including summary of learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GorZCdSHjYa"
   },
   "source": [
    "---\n",
    "\n",
    "## **1. About this project**\n",
    "\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set used and made famous by the British statistician and biologist Ronald Fisher in his 1936 paper \"The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.\" (1)\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "The goal of this project is to build a simple neural network that will classify samples correctly based on these four features.\n",
    "\n",
    "**References:**\n",
    "\n",
    "1. R. A. Fisher (1936). \"The use of multiple measurements in taxonomic problems\". Annals of Eugenics. 7 (2): 179-188\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **2. Implementation approach: building a neural network from first principles**\n",
    "\n",
    "This notebook demonstrates, step by step, how a simple neural network can be built and trained **from first principles** (without using deep learning libraries) to classify species of Iris flower based on the four features.\n",
    "\n",
    "**Objectives:**  \n",
    "- Build every part of the network by hand: weight initialization, activation functions, forward and backward passes, and gradient descent.\n",
    "- Show and explain all the maths underpinning the process.\n",
    "- Visualize and interpret results at each step.\n",
    "- Explore how changing model parameters affects performance.\n",
    "\n",
    "> All equations are shown explicitly, so you can truly see \"under the hood\" of a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Network architecture**  \n",
    "\n",
    "The simple neural network implemented is a perceptron model with one hidden layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Swzd_12cxp6V"
   },
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1mbRPZHaJTkO9djR6l1NY7WBWSUOWPbQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input Layer: 4 units, one for each feature of the Iris dataset (sepal length, sepal width, petal length, petal width).\n",
    "- Hidden Layer: Starts with 6 units (this is a tunable hyperparameter; later experimentation will find the optimal number for this problem).\n",
    "- Output Layer: 3 units, each representing one of the Iris species.\n",
    "\n",
    "**Activation functions:**\n",
    "\n",
    "- **ReLU** (Rectified Linear Unit) for the hidden layer:  \n",
    "  $\\mathrm{ReLU}(x) = \\max(0, x)$\n",
    "\n",
    "- **Softmax** for the output layer:  \n",
    "  $\\mathrm{softmax}(z_j) = \\dfrac{e^{z_j}}{\\sum_{l=1}^{k} e^{z_l}}$,  \n",
    "  where $k$ is the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data flow and matrix shapes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1jrJJNIYagcRqipLiY8ehy6fpDE7re0gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $n$ is the number of samples and $h$ is the size of the hidden layer:\n",
    "\n",
    "- Input matrix: $\\mathbf{a}_0 \\in \\mathbb{R}^{n \\times 4}$\n",
    "- First layer weights: $\\mathbf{w}_1 \\in \\mathbb{R}^{4 \\times h}$\n",
    "- First layer biases: $\\mathbf{b}_1 \\in \\mathbb{R}^{1 \\times h}$\n",
    "- Hidden activations: $\\mathbf{a}_1 \\in \\mathbb{R}^{n \\times h}$\n",
    "- Second layer weights: $\\mathbf{w}_2 \\in \\mathbb{R}^{h \\times 3}$\n",
    "- Second layer biases: $\\mathbf{b}_2 \\in \\mathbb{R}^{1 \\times 3}$\n",
    "- Output probabilities: $\\mathbf{a}_2 \\in \\mathbb{R}^{n \\times 3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset characteristics and evaluation strategy**\n",
    "\n",
    "- The Iris Dataset is extremely small - containing only 150 samples:\n",
    "  - 80% of the data is used for training (no validation dataset used)\n",
    "  - 20% of the data is reserved as a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Deployment plan**\n",
    "\n",
    "- Once the model is trained and optimized, it can be **packaged in a Docker image** alongside a **FastAPI application** to serve predictions.\n",
    "- The container can be deployed to a production environment (e.g., bare metal server), using a process manager (like `systemd`) or container orchestration for reliability.\n",
    "- Observability (logging and metrics) will be integrated for monitoring model usage and health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full code is included in the GitHub repository - https://github.com/markhodierne/iris-recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txw4hkDYH5c9"
   },
   "source": [
    "---\n",
    "## **3. Imports and random seed**\n",
    "\n",
    "Only the following core scientific Python libraries are used:\n",
    "- **NumPy** for array and matrix operations\n",
    "- **Pandas** for data handling\n",
    "- **Matplotlib** for plotting and visualization\n",
    "- **Scikit-learn** (only for data loading, train-test splitting, and EDA)\n",
    "\n",
    "A fixed random seed ensures all results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6580,
     "status": "ok",
     "timestamp": 1747404562593,
     "user": {
      "displayName": "Mark Hodierne",
      "userId": "10268299263793004126"
     },
     "user_tz": -60
    },
    "id": "0Jofp0V2yyVV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set global random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. Loading and preprocessing the Iris dataset**\n",
    "\n",
    "The **Iris dataset** consists of 150 flower samples from three different species (*Setosa*, *Versicolor*, *Virginica*).  \n",
    "Each sample has four features:\n",
    "- sepal length\n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width\n",
    "\n",
    "We will:\n",
    "1. Load the data\n",
    "2. Prepare the feature matrix $\\mathbf{X}$ and one-hot encoded labels $\\mathbf{Y}$\n",
    "3. Split the data into training and test sets\n",
    "\n",
    "**Mathematical notation:**\n",
    "Let $n$ be the number of samples, $d$ the number of features (here $d=4$), and $k$ the number of classes (here $k=3$):\n",
    "- $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$\n",
    "- $\\mathbf{Y} \\in \\{0,1\\}^{n \\times k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and preprocess\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(\n",
    "    data=np.column_stack([iris.data, iris.target]),\n",
    "    columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n",
    ")\n",
    "iris_df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "# Create a features matrix X with dimensions (150, 4)\n",
    "X = iris_df[['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid']].values\n",
    "\n",
    "# Create a labels matrix y with dimensions (150, 3)\n",
    "y = pd.get_dummies(iris_df['class']).to_numpy()\n",
    "\n",
    "# Create train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=21\n",
    ")\n",
    "\n",
    "# Modify datasets to single sample for testing\n",
    "#X_train = X_train[0].reshape(1, -1)\n",
    "#y_train = y_train[0].reshape(1, -1)\n",
    "\n",
    "# Modify datasets to first 4 samples for testing\n",
    "#X_train = X_train[:5, :]\n",
    "#y_train = y_train[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. Data exploration**\n",
    "\n",
    "inspect the first few rows of the data and its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1747404573517,
     "user": {
      "displayName": "Mark Hodierne",
      "userId": "10268299263793004126"
     },
     "user_tz": -60
    },
    "id": "YNk66Itn2eaU",
    "outputId": "967d7ae7-f700-4a35-ebe2-217df9164c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_len  sepal_wid  petal_len  petal_wid  class\n",
      "0        5.1        3.5        1.4        0.2    0.0\n",
      "1        4.9        3.0        1.4        0.2    0.0\n",
      "2        4.7        3.2        1.3        0.2    0.0\n",
      "3        4.6        3.1        1.5        0.2    0.0\n",
      "4        5.0        3.6        1.4        0.2    0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sepal_len  150 non-null    float64\n",
      " 1   sepal_wid  150 non-null    float64\n",
      " 2   petal_len  150 non-null    float64\n",
      " 3   petal_wid  150 non-null    float64\n",
      " 4   class      150 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 6.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data exploration (optional)\n",
    "print(iris_df.head())\n",
    "print(iris_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjc02R8OM0AS"
   },
   "source": [
    "---\n",
    "## **6. Exploratory visualization: K-Means clustering**\n",
    "\n",
    "To visualize the structure of the Iris dataset, we perform K-Means clustering. This analysis shows that one flower species is linearly separable from the other two, but the other two are not linearly separable from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ru-JgMRfK8Yj",
    "outputId": "80930c49-7139-4d33-f705-50640aac8a4e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# K-means clustering for EDA (optional)\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(k):\n",
    "    cluster_points = X[labels == i]\n",
    "    plt.scatter(\n",
    "        cluster_points[:, 0],\n",
    "        cluster_points[:, 1],\n",
    "        label=f'Cluster {i+1}'\n",
    "    )\n",
    "\n",
    "plt.scatter(\n",
    "    cluster_centers[:, 0],\n",
    "    cluster_centers[:, 1],\n",
    "    marker='x',\n",
    "    color='k',\n",
    "    label='Cluster Centers'\n",
    ")\n",
    "plt.title('K-Means Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **7. Activation and loss functions**\n",
    "\n",
    "#### ReLU activation\n",
    "\n",
    "Rectified Linear Unit (ReLU) is defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{ReLU}(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "Derivative (used in backpropagation):\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} \\mathrm{ReLU}(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x > 0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### Softmax activation\n",
    "\n",
    "Used in the output layer for multiclass classification:\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(z_j) = \\frac{e^{z_j}}{\\sum_{l=1}^{k} e^{z_l}}\n",
    "$$\n",
    "\n",
    "#### Cross-Entropy loss\n",
    "\n",
    "For true label vector $\\mathbf{y}$ and predicted probabilities $\\hat{\\mathbf{y}}$:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) = -\\sum_{j=1}^k y_j \\log(\\hat{y}_j)\n",
    "$$\n",
    "\n",
    "This loss is averaged over all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions (activation, loss)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    # Subtract the max value of x to ensure numerical stability\n",
    "    x -= np.max(x, axis=1, keepdims=True)\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    epsilon = 1e-12\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. Building a neural network from scratch**\n",
    "\n",
    "We build a neural network with:\n",
    "- One hidden layer (with ReLU activation)\n",
    "- Output layer (with Softmax activation)\n",
    "- Fully explicit forward and backward calculations\n",
    "\n",
    "Network architecture:\n",
    "- Input: $d$ features\n",
    "- Hidden layer: $h$ units\n",
    "- Output: $k$ units (classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Forward Pass**\n",
    "\n",
    "Given input $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$:\n",
    "- Hidden pre-activation: $\\mathbf{Z}_1 = \\mathbf{X}\\mathbf{W}_1 + \\mathbf{b}_1$\n",
    "- Hidden activation: $\\mathbf{A}_1 = \\mathrm{ReLU}(\\mathbf{Z}_1)$\n",
    "- Output pre-activation: $\\mathbf{Z}_2 = \\mathbf{A}_1\\mathbf{W}_2 + \\mathbf{b}_2$\n",
    "- Output activation: $\\mathbf{A}_2 = \\mathrm{softmax}(\\mathbf{Z}_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Backward Pass (Backpropagation)**\n",
    "\n",
    "Gradients (for one batch):\n",
    "\n",
    "- Output error:\n",
    "$$\n",
    "\\delta_2 = \\mathbf{A}_2 - \\mathbf{Y}\n",
    "$$\n",
    "- Output weights/bias gradients:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{W}_2} = \\mathbf{A}_1^\\top \\delta_2\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{b}_2} = \\sum \\delta_2\n",
    "$$\n",
    "- Hidden layer error:\n",
    "$$\n",
    "\\delta_1 = (\\delta_2 \\mathbf{W}_2^\\top) \\odot \\mathrm{ReLU}'(\\mathbf{Z}_1)\n",
    "$$\n",
    "- Hidden weights/bias gradients:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{W}_1} = \\mathbf{X}^\\top \\delta_1\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{b}_1} = \\sum \\delta_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gradient Descent Update**\n",
    "For each parameter $\\theta$:\n",
    "$$\n",
    "\\theta := \\theta - \\eta \\frac{\\partial L}{\\partial \\theta}\n",
    "$$\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initializing weights and biases**\n",
    "\n",
    "- Hidden Layer (ReLU Activation): Use He initialization, which scales random values from a standard normal distribution (mean = 0, variance = 1), so the variance is approximately (2/hidden_units). This helps prevent vanishing or exploding gradients, which can occur with ReLU activations. Biases are initialized to 0 values.\n",
    "\n",
    "- Output Layer (Softmax Activation): Use Xavier initialization, which scales random values from a standard normal distribution (mean = 0, variance = 1), so the variance is approximately (1/hidden_units). This is well-suited for sigmoid-like activations such as softmax. Biases are initialized to 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neural network class from scratch\n",
    "\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights for the input to hidden layer (He initialization)\n",
    "        self.w1 = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        # Initialize weights for the hidden to output layer (Xavier initialization)\n",
    "        self.w2 = np.random.randn(hidden_size, output_size) * np.sqrt(1. / hidden_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.z1 = X @ self.W1 + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = self.a1 @ self.W2 + self.b2\n",
    "        self.a2 = softmax(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y_true, y_pred):\n",
    "        m = X.shape[0]\n",
    "        dz2 = y_pred - y_true\n",
    "        dw2 = self.a1.T @ dz2 / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        da1 = dz2 @ self.W2.T\n",
    "        dz1 = da1 * relu_derivative(self.z1)\n",
    "        dw1 = X.T @ dz1 / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "        self.w2 -= self.learning_rate * dw2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.w1 -= self.learning_rate * dw1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "\n",
    "    def train(self, X, y, epochs=100, batch_size=16):\n",
    "        history = {'loss': [], 'acc': []}\n",
    "        n_samples = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i + batch_size]\n",
    "                y_batch = y_shuffled[i:i + batch_size]\n",
    "                y_pred = self.forward(X_batch)\n",
    "                self.backward(X_batch, y_batch, y_pred)\n",
    "            y_train_pred = self.forward(X)\n",
    "            train_loss = cross_entropy(y_train_pred, y)\n",
    "            train_acc = np.mean(np.argmax(y_train_pred, axis=1) == np.argmax(y, axis=1))\n",
    "            history['loss'].append(train_loss)\n",
    "            history['acc'].append(train_acc)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs} | Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "        return history\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the predicted probability distribution over classes for each sample.\n",
    "        \"\"\"\n",
    "        return self.forward(X)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the predicted class label (integer) for each sample.\n",
    "        \"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.argmax(proba, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **9. Training setup and hyperparameters**\n",
    "\n",
    "Specify the network hyperparameters:\n",
    "- Number of input features ($d = 4$)\n",
    "- Number of hidden layer units ($h$, to be tuned)\n",
    "- Number of output classes ($k = 3$)\n",
    "- Learning rate ($\\eta$)\n",
    "- Number of training epochs\n",
    "- Batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 6\n",
    "output_size = y_train.shape[1]\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **10. Instantiate the neural network**\n",
    "\n",
    "Create neural network model with the parameters defined above.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "nn = SimpleNeuralNetwork(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    learning_rate=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **11. Train the neural network**\n",
    "\n",
    "The model is trained using **mini-batch gradient descent**.  \n",
    "At each epoch, the following steps occur:\n",
    "1. Shuffle the training data\n",
    "2. Split into batches and perform forward/backward passes\n",
    "3. Update weights and biases using gradients\n",
    "4. Compute training loss/accuracy and monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = nn.train(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **12. Visualizing training loss/accuracy**\n",
    "\n",
    "The loss and accuracy curves show how the model learns over time.  \n",
    "- Loss should decrease\n",
    "- Accuracy should increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and accuracy curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['acc'], label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **13. Evaluating the model on test data**\n",
    "\n",
    "To measure the final model performance, compute:\n",
    "- Test set **cross-entropy loss**\n",
    "- Test set **classification accuracy**\n",
    "\n",
    "Accuracy is defined as:\n",
    "$$\n",
    "\\mathrm{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "y_test_pred = nn.forward(X_test)\n",
    "test_loss = cross_entropy(y_test_pred, y_test)\n",
    "test_acc = np.mean(np.argmax(y_test_pred, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **14. Confusion Matrix**\n",
    "\n",
    "A **confusion matrix** shows where the model gets confused between classes.\n",
    "\n",
    "For multiclass classification, the entry at $(i, j)$ is the number of samples from true class $i$ predicted as class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = nn.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **15. Experiment: How does hidden layer size affect performance?**\n",
    "\n",
    "We now sweep the **hidden layer size** and observe its effect on validation accuracy.\n",
    "\n",
    "Try different values of $h$ and plot:\n",
    "- Hidden size vs. validation accuracy\n",
    "\n",
    "This gives insight into the networkâ€™s **capacity** and risk of **under/overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: Tune hidden layer size\n",
    "hidden_sizes = [2, 4, 6, 8, 12]\n",
    "test_accuracies = []\n",
    "\n",
    "for h in hidden_sizes:\n",
    "    nn = SimpleNeuralNetwork(\n",
    "        input_size=input_size,\n",
    "        hidden_size=h,\n",
    "        output_size=output_size,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    _ = nn.train(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    y_pred = nn.forward(X_test)\n",
    "    acc = np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_test, axis=1))\n",
    "    test_accuracies.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **16. Results: hidden layer size vs. validation accuracy**\n",
    "\n",
    "We visualize how model capacity affects performance.  \n",
    "- Too small a hidden layer: **underfits**\n",
    "- Too large: risk of **overfitting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation accuracy vs. hidden layer size\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(hidden_sizes, test_accuracies, marker='o')\n",
    "plt.title(\"Validation Accuracy vs. Hidden Layer Size\")\n",
    "plt.xlabel(\"Hidden Layer Size\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **17. Experiment: Effect of temperature on the Softmax function**\n",
    "\n",
    "In this section, I explore how temperature scaling affects the behavior of the Softmax function in the neural network's output layer.\n",
    "\n",
    "### What Is temperature in Softmax?\n",
    "\n",
    "The standard softmax function is defined as:\n",
    "$$\n",
    "\\mathrm{softmax}(z_j) = \\frac{\\exp(z_j)}{\\sum_{l=1}^k \\exp(z_l)}\n",
    "$$\n",
    "where $\\mathbf{z}$ is the vector of logits (raw output values) for each class, and $k$ is the number of classes.\n",
    "\n",
    "**Temperature scaling** introduces a parameter $T > 0$ to control the \"peakiness\" of the softmax output:\n",
    "$$\n",
    "\\mathrm{softmax}_T(z_j) = \\frac{\\exp(z_j / T)}{\\sum_{l=1}^k \\exp(z_l / T)}\n",
    "$$\n",
    "\n",
    "- When $T = 1$, this reduces to the standard softmax.\n",
    "- When $T < 1$, the output distribution becomes more \"peaked\" (more confident predictions).\n",
    "- When $T > 1$, the distribution becomes more \"uniform\" (less confident, more exploratory).\n",
    "\n",
    "### Why Adjust Temperature?\n",
    "\n",
    "- **Calibrating model confidence:** In some applications (e.g., reinforcement learning, sampling, uncertainty estimation), adjusting $T$ can help control how \"confident\" or \"uncertain\" the network's predictions are.\n",
    "- **Exploration vs. exploitation:** High temperature encourages exploration; low temperature enforces exploitation (choosing the most probable class more deterministically).\n",
    "\n",
    "### In this experiment\n",
    "\n",
    "I vary the temperature parameter $T$ and observe how it changes the output probabilities of the neural network and the predicted class distributions on the Iris test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, tau):\n",
    "    # Subtract the max value of x to ensure numerical stability\n",
    "    x -= np.max(x, axis=1, keepdims=True)\n",
    "    e_x = np.exp(x / tau)\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "ZZ = np.array([[19, 20, 18]]).reshape(1, -1)\n",
    "\n",
    "# Standard softmax\n",
    "A_std = softmax(ZZ, 1)[0]\n",
    "\n",
    "# High Temperature softmax\n",
    "A_high = softmax(ZZ, 5)[0]\n",
    "\n",
    "# Low temperature softmax\n",
    "A_low = softmax(ZZ, 0.2)[0]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(dpi=120)\n",
    "plt.plot(A_std, label='Temperature $T=1$ (Standard Softmax)')\n",
    "plt.plot(A_high, label='High Temperature ($T>1$)')\n",
    "plt.plot(A_low, label='Low Temperature ($T<1$)')\n",
    "plt.title('Effect of Softmax Temperature on Output Probabilities')\n",
    "plt.xlabel('Class Index or Sample Index')\n",
    "plt.ylabel('Predicted Probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyTWSAsqwzAv"
   },
   "source": [
    "---\n",
    "\n",
    "# **DO NOT CONSIDER ANY OF THE CELLS BEYOND THIS POINT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wUV1ikYRhGe"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def back_propagation(X, y_true, a1, a2, learning_rate):\n",
    "    # Back propagation algorithm to compute the gradients and update weights and biases\n",
    "\n",
    "    global w1, b1, w2, b2\n",
    "\n",
    "    # Previous code attempt - how is this different from below?\n",
    "    #da2 = -np.divide(y_true, a2)\n",
    "    #dz2 = da2 * (a2 * (1 - a2))\n",
    "\n",
    "    # Compute gradients\n",
    "    dz2 = a2 - y_true\n",
    "    dw2 = np.dot(a1.T, dz2)\n",
    "    db2 = np.sum(dz2, axis=0)\n",
    "    da1 = np.dot(dz2, w2.T)\n",
    "    dz1 = da1 * relu_derivative(a1)\n",
    "    dw1 = np.dot(X.T, dz1)\n",
    "    db1 = np.sum(dz1, axis=0)\n",
    "\n",
    "    # Update weights and biases\n",
    "    w1 -= learning_rate * dw1\n",
    "    b1 -= learning_rate * db1\n",
    "    w2 -= learning_rate * dw2\n",
    "    b2 -= learning_rate * db2\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_batches(X, y, batch_size):\n",
    "    num_samples = len(X)\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)  # Shuffle indices to randomize the data\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        yield X[batch_indices], y[batch_indices]\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    max_indices = np.argmax(y_pred, axis=1)\n",
    "    y_pred_encoded = np.zeros(y_pred.shape, dtype=int)\n",
    "    rows = np.arange(y_pred.shape[0])\n",
    "    y_pred_encoded[rows, max_indices] = 1\n",
    "    accuracy = np.mean(np.all(y_pred_encoded == y_true, axis=1)) * 100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6nJSFxAlis4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # CHECK THESE CALCULATIONS\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "    def _forward(\n",
    "        self, X:\n",
    "        np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        z1 = np.dot(X, self.w1) + self.b1  # (n, hidden)\n",
    "        a1 = _relu(z1)\n",
    "        z2 = np.dot(a1, self.w2) + self.b2  # (n, output)\n",
    "        a2 = _softmax(z2)\n",
    "        return a1, a2, z1\n",
    "\n",
    "    def _backward(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        a1: np.ndarray,\n",
    "        a2: np.ndarray,\n",
    "        z1: np.ndarray\n",
    "    ) -> None:\n",
    "        n = X.shape[0]\n",
    "        dz2 = (a2 - y) / n        # (n, output)\n",
    "        dw2 = np.dot(a1.T, dz2)   # (hidden, output)\n",
    "        db2 = np.sum(dz2, axis=0)\n",
    "\n",
    "        da1 = np.dot(dz2, self.w2.T)        # (n, hidden)\n",
    "        dz1 = da1 * _relu_derivative(z1)    # (n, hidden)\n",
    "        dw1 = np.dot(X.T, dz1)              # (input, hidden)\n",
    "        db1 = np.sum(dz1, axis=0)\n",
    "\n",
    "        # Previous code attempt - how is this different from above?\n",
    "        #da2 = -np.divide(y_true, a2)\n",
    "        #dz2 = da2 * (a2 * (1 - a2))\n",
    "\n",
    "        # what is this calculation - different from above\n",
    "        #dz2 = a2 - y_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wdXq1jHgsUj"
   },
   "source": [
    "NEXT STEPS\n",
    "\n",
    "Comment code and add all the maths calcs\n",
    "Implement Stochastic Gradient Descent (??)\n",
    "Implement early stopping\n",
    "Make the training cycle a function so my main is minimal and can be repeated for different scenarios (maybe parameterize and then can easily compare scenario results.\n",
    "How to 'see' this data as a cluster map? Hypothesis that it is easy to classify - run a logistic regression on it.\n",
    "Implement K-folds - and other methods to make the best of a small dataset.\n",
    "Synthetic data?\n",
    "Implement temperature on the softmax and play with this.\n",
    "Create alternative BP calcs with a2 and z2 rather than just z2 - review the maths.\n",
    "Review detailed YT vids and implement NN as a class.\n",
    "Comment on the sensitivity of the model to hyperparameters.\n",
    "Implement dropout to randomly turn to zero a fraction of nodes - is this to prevent overfitting?\n",
    "\n",
    "If you have a small dataset, consider augmenting your training data with transformations such as rotation, translation, or flipping. Data augmentation can provide the model with more diverse examples to learn from and prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "If your neural network is converging too quickly and then getting stuck at a suboptimal solution, you can try several techniques to slow down the convergence and potentially reach a better solution:\n",
    "\n",
    "Reduce Learning Rate: Decrease the learning rate to slow down the updates to the model parameters. A smaller learning rate allows the model to explore the parameter space more gradually, potentially avoiding getting stuck in local minima.\n",
    "\n",
    "Learning Rate Scheduling: Instead of using a fixed learning rate throughout training, consider using learning rate scheduling techniques such as exponential decay or step decay to gradually reduce the learning rate over epochs. This can help the model to converge more gradually.\n",
    "\n",
    "Early Stopping: Monitor the validation performance of the model during training and stop training when the validation performance stops improving. Early stopping prevents overfitting and allows the model to find a better solution.\n",
    "\n",
    "Batch Normalization: Use batch normalization layers in your neural network. Batch normalization can stabilize training by normalizing the activations of each layer and reducing the internal covariate shift, which can lead to faster convergence and better performance.\n",
    "\n",
    "Regularization: Apply regularization techniques such as L1 or L2 regularization, dropout, or weight decay to prevent overfitting and improve generalization. Regularization can help the model to learn more slowly and generalize better to unseen data.\n",
    "\n",
    "Increase Model Complexity: If your model is too simple, it may struggle to learn complex patterns in the data. Consider increasing the capacity of your model by adding more layers or units to better capture the underlying structure of the data.\n",
    "\n",
    "Data Augmentation: If you have a small dataset, consider augmenting your training data with transformations such as rotation, translation, or flipping. Data augmentation can provide the model with more diverse examples to learn from and prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "Fluctuations in validation accuracy between epochs can occur due to several reasons:\n",
    "\n",
    "Small Validation Set: If your validation set is small, it may not be representative of the overall distribution of the data. As a result, the validation accuracy can fluctuate between epochs due to random variations in the samples selected for validation.\n",
    "\n",
    "High Learning Rate: A high learning rate can cause the model to oscillate around the optimal solution, leading to fluctuations in validation accuracy. Consider reducing the learning rate to stabilize training.\n",
    "\n",
    "Model Instability: If the model architecture is unstable or if the training process is not properly regularized, the model may exhibit oscillations in performance between epochs. Regularization techniques such as dropout, weight decay, or batch normalization can help stabilize training.\n",
    "\n",
    "Early Stopping: If you're using early stopping based on validation performance, fluctuations in validation accuracy can occur as the training is stopped when the validation performance does not improve for a certain number of epochs. This can result in variations in the final validation accuracy depending on when the training is stopped.\n",
    "\n",
    "Data Variability: If the validation set contains highly variable or noisy samples, the model may perform differently on different subsets of the validation data, leading to fluctuations in validation accuracy.\n",
    "\n",
    "Model Complexity: If the model is too complex relative to the size of the training data or if the model capacity is not well matched to the complexity of the task, the model may overfit the training data, leading to fluctuations in validation accuracy.\n",
    "\n",
    "To address fluctuations in validation accuracy, you can try the following:\n",
    "\n",
    "Increase the size of the validation set to improve its representativeness.\n",
    "Experiment with different learning rates and regularization techniques to stabilize training.\n",
    "Use techniques such as early stopping or model averaging to prevent overfitting and improve generalization performance.\n",
    "Ensure that the model architecture and complexity are appropriate for the task and dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtKf84y-WoeU"
   },
   "source": [
    "Stuff re FastAPI\n",
    "\n",
    "curl -X POST http://127.0.0.1:8000/which_species_is_this \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"sepal_len\": 5.1, \"sepal_wid\": 3.5, \"petal_len\": 1.4, \"petal_wid\": 0.2}'\n",
    "Change 127.0.0.1 to your own ip\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4Mnqw2ysVYc"
   },
   "source": [
    "---\n",
    "\n",
    "# **5. Resources**\n",
    "\n",
    "RMSProp and ADAM\n",
    "https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be\n",
    "\n",
    "https://towardsdatascience.com/a-visual-explanation-of-gradient-descent-methods-momentum-adagrad-rmsprop-adam-f898b102325c\n",
    "\n",
    "Building makemore Part 4: Becoming a Backprop Ninja\n",
    "https://www.youtube.com/watch?v=q8SA3rM6ckI&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=6&t=939s\n",
    "\n",
    "\n",
    "Matrix multiplication animation\n",
    "https://www.youtube.com/watch?v=1hf_cHNbgCk\n",
    "\n",
    "\n",
    "The Matrix Calculus You Need For Deep Learning\n",
    "https://explained.ai/matrix-calculus/#sec:1.2\n",
    "\n",
    "\n",
    "\n",
    "Softmax derivative\n",
    "https://davidbieber.com/snippets/2020-12-12-derivative-of-softmax-and-the-softmax-cross-entropy-loss/\n",
    "https://www.mldawn.com/the-derivative-of-softmaxz-function-w-r-t-z/\n",
    "\n",
    "```\n",
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n",
    "```\n",
    "\n",
    "Deploy ML models with FastAPI, Docker, and Heroku | Tutorial\n",
    "https://www.youtube.com/watch?v=h5wLuVDr0oc\n",
    "\n",
    "Dockerize FastAPI project like a pro - Step-by-step Tutorial\n",
    "https://www.youtube.com/watch?si=ll6mFzr_MblIIsGE&v=CzAyaSolZjY&feature=youtu.be\n",
    "\n",
    "5 Examples of Nonlinear Relationships Between Variables\n",
    "https://www.statology.org/nonlinear-relationship-examples/\n",
    "\n",
    "Setting your username in Git\n",
    "https://docs.github.com/en/get-started/getting-started-with-git/setting-your-username-in-git\n",
    "\n",
    "Getting Git right\n",
    "https://www.atlassian.com/git\n",
    "\n",
    "Why You NEED To Learn FastAPI | Hands On Project\n",
    "https://www.youtube.com/watch?v=cbASjoZZGIw\n",
    "\n",
    "Weight Initialization explained | A way to reduce the vanishing gradient problem  \n",
    "https://www.youtube.com/watch?v=8krd5qKVw-Q\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
